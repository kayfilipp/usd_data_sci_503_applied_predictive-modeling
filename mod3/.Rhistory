knitr::opts_chunk$set(echo = TRUE)
require(caret)
nzv <- nearZeroVar(fingerprints)
library(AppliedPredictiveModeling)
data(permeability)
require(caret)
nzv <- nearZeroVar(fingerprints)
fingerprints.df <- fingerprints[,-nzv]
length(colnames(fingerprints.df))
#partition the training and test sets.
predictors = as.data.frame(fingerprints.df)
response   = as.data.frame(permeability)
set.seed(1)
trainingRows <- createDataPartition(predictors[,1],p = 0.80, list=FALSE)
trainPredict <- predictors[trainingRows,]
trainResponse<- response[trainingRows,]
testPredict  <- predictors[-trainingRows,]
testResponse <- response[-trainingRows,]
#pre-process data
pp.train <- preProcess(trainPredict,method=c("center","scale","BoxCox"))
pp.test  <- preProcess(testPredict,method=c("center","scale","BoxCox"))
trainPredict <- predict(pp.train,newdata=trainPredict)
testPredict  <- predict(pp.test,newdata=testPredict)
paste("Training Size:",nrow(trainPredict),"Testing Size:",nrow(testPredict))
#model: pls
require(pls)
require(dplyr)
set.seed(1)
pls <- train(x=trainPredict,y=trainResponse, method="pls",tunelength=20,trControl = ctrl, preProc=c("center","scale"))
#model: pls
ctrl <- trainControl(method="cv",number=10)
require(pls)
require(dplyr)
set.seed(1)
pls <- train(x=trainPredict,y=trainResponse, method="pls",tunelength=20,trControl = ctrl, preProc=c("center","scale"))
print(paste("Optimal tuning parameter: number of components",pls$bestTune$ncomp))
xyplot(resid(pls)~ predict(pls),type=c("p","g"),xlab="predicted",ylab="residuals",main="predicted vs. residual values for pls")
#model: pls
ctrl <- trainControl(method="cv",number=10)
require(pls)
require(dplyr)
set.seed(1)
pls <- train(x=trainPredict,y=trainResponse, method="pls",tunelength=20,trControl = ctrl)
print(paste("Optimal tuning parameter: number of components",pls$bestTune$ncomp))
xyplot(resid(pls)~ predict(pls),type=c("p","g"),xlab="predicted",ylab="residuals",main="predicted vs. residual values for pls")
pls.predict <- predict(pls,newdata = testPredict,ncomp = 1:2) %>% as.numeric()
print(RMSE(pls.predict,testResponse))
print(caret::R2(pls.predict,testResponse))
print(paste("Optimal tuning parameter: number of components",pls$bestTune$ncomp))
xyplot(pls.predict~testResponse,type=c("p","g"),xlab="predicted",ylab="observed",main="Observed vs. predicted values for pls")
#ols: we cannot conduct ols on this model without first applying PCA.
set.seed(1)
ols <- train(x = trainPredict,y=trainResponse,method="lm",trControl = ctrl,preProcess = "pca")
ols.predict <- predict(ols,newdata = testPredict)
print(RMSE(ols.predict,testResponse))
print(caret::R2(ols.predict,testResponse))
#penalized regression model: ridge regression
require(elasticnet)
ridgeGrid <- data.frame(.lambda = seq(0,.1,length = 15))
set.seed(1)
ridge.reg <- train(trainPredict,trainResponse,method="ridge",tuneGrid = ridgeGrid,trControl=ctrl)
ridge.reg
library(glmnet)
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(trainPredict, trainResponse, alpha = 1)
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(as.matrix(trainPredict), trainResponse, alpha = 1)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
best_model <- glmnet(as.matrix(trainPredict), trainResponse, alpha = 1, lambda = best_lambda)
lasso <- predict(best_model, s = best_lambda, newx = testPredict)
lasso <- predict(best_model, s = best_lambda, newx = as.matrix(testPredict))
lasso
lasso %>% length
caret
require(caret)
print(caret::R2())
print(caret::R2(lasso,testResponse))
print(caret::RMSE(lasso,testResponse))
ridge.reg <- train(trainPredict,trainResponse,method="ridge",tuneGrid = ridgeGrid,trControl=ctrl)
#penalized regression: Lasso regression
set.seed(1)
enetModel<- enet(x = as.matrix(trainPredict), y = trainResponse, lambda = 0, normalize = FALSE)
enetPred <- predict(enetModel, newx = as.matrix(testPredict), s = .1, mode = "fraction", type = "fit")
r_squared = caret::R2(enetPred$fit,testResponse)
ridge_rmse= RMSE(enetPred$fit,testResponse)
paste(r_squared,ridge_rmse)
enetGrid <- expand.grid(.lambda = c(0, 0.01, .1), .fraction = seq(.05, 1, length = 20))
set.seed(1)
enetTune <- train(trainPredict,trainResponse,method = "enet",tuneGrid = enetGrid,trControl = ctrl)
enetGrid <- expand.grid(.lambda = c(0, 0.01, .1), .fraction = seq(.05, 1, length = 20))
set.seed(1)
enetTune <- train(trainPredict,trainResponse,method = "enet",tuneGrid = enetGrid,trControl = ctrl)
enetpredict = predict(enetTune, newx=testPredict, s=.1, type = "fit", mode ="fraction")
enetpredict = predict(enetTune, newx=testPredict, s=.1, type = "raw", mode ="fraction")
enetPredict
enetpredict
testResponse
enetpredict = predict(enetTune, newx=as.matrix(testPredict), s=.1, type = "raw", mode ="fraction")
enetpredict
enetpredict %>% length
enetpredict$
s
enetpredict = predict(enetTune, newx=as.matrix(testPredict), s=.1, type = "coefficients", mode ="fraction")
enetpredict = predict(enetTune, newx=as.matrix(testPredict), s=.1, type = "raw", mode ="fraction")
enetpredict
testPredict
testPredict %>% nrow
enetpredict = predict(enetTune, newx=(testPredict), s=.1, type = "raw", mode ="fraction")
enetpredict
enetpredict %>% nrow
enetpredict %>% nrow()
enetpredict %>% nrows
enetpredict %>% lenth
enetpredict %>% length
enetTune$bestTune
fraction.b = enetTune$bestTune$fraction
lambda.b = enetTune$bestTune$lambda
enetModel <- enet(x = as.matrix(trainPredict), y = trainpredict, lambda = lambda.b,fraction=fraction.b, normalize = TRUE)
enetModel <- enet(x = as.matrix(trainPredict), y = trainpredict, lambda = lambda.b, normalize = TRUE)
enetModel <- enet(x = as.matrix(trainPredict), y = trainpredict, lambda = lambda.b, normalize = FALSE)
enetModel <- enet(x = as.matrix(trainPredict), y = trainResponse, lambda = lambda.b, normalize = FALSE)
enetModel
enetPred <- predict(enetModel, newx = as.matrix(testPredict), s = fraction.b, mode = "fraction", type = "fit")
enetPred
caret::RMSE()
caret::R2(enetPred$fit,testResponse) %>% print
caret::RMSE(enetPred$fit,testResponse) %>% print
enetGrid <- expand.grid(.lambda = c(0, 0.01, .1), .fraction = seq(.05, 1, length = 20))
set.seed(1)
enetTune <- train(trainPredict,trainResponse,method = "enet",tuneGrid = enetGrid,trControl = ctrl,preProcess = "PCA")
enetGrid <- expand.grid(.lambda = c(0, 0.01, .1), .fraction = seq(.05, 1, length = 20))
set.seed(1)
enetTune <- train(trainPredict,trainResponse,method = "enet",tuneGrid = enetGrid,trControl = ctrl,preProcess = c("center","scale","BoxCox"))
fraction.b = enetTune$bestTune$fraction
lambda.b = enetTune$bestTune$lambda
enetModel <- enet(x = as.matrix(trainPredict), y = trainResponse, lambda = lambda.b, normalize = FALSE)
enetPred <- predict(enetModel, newx = as.matrix(testPredict), s = fraction.b, mode = "fraction", type = "fit")
caret::R2(enetPred$fit,testResponse) %>% print
caret::RMSE(enetPred$fit,testResponse) %>% print
enetPred <- predict(enetModel, newx = as.matrix(testPredict), s = 0.1, mode = "fraction", type = "fit")
caret::R2(enetPred$fit,testResponse) %>% print
caret::RMSE(enetPred$fit,testResponse) %>% print
enetTune <- train(trainPredict,trainResponse,method = "enet",tuneGrid = enetGrid,trControl = ctrl)
enetTune <- train(trainPredict,trainResponse,method = "enet",tuneGrid = enetGrid,trControl = ctrl)
fraction.b = enetTune$bestTune$fraction
lambda.b = enetTune$bestTune$lambda
enetModel <- enet(x = as.matrix(trainPredict), y = trainResponse, lambda = lambda.b, normalize = FALSE)
enetPred <- predict(enetModel, newx = as.matrix(testPredict), s = 0.1, mode = "fraction", type = "fit")
caret::R2(enetPred$fit,testResponse) %>% print
caret::RMSE(enetPred$fit,testResponse) %>% print
library(AppliedPredictiveModeling)
data(chemicalManufacturingProcess)
#knn imputation
predictors <-impute.knn(processPredictors ,k = 5, rowmax = 0.5, colmax = 0.8, maxp = 1500) %>% as.data.frame
#knn imputation
require(impute)
install.packages("impute")
#knn imputation
require(impute)
#knn imputation
knn.impute()
require(bnstruct)
predictors <-knn.impute(processPredictors, k = 5) %>% as.data.frame
library(AppliedPredictiveModeling)
data(chemicalManufacturingProcess)
data("ChemicalManufacturingProcess")
processPredictors
yield
data(ChemicalManufacturingProcess)
library(AppliedPredictiveModeling)
data(ChemicalManufacturingProcess)
#knn imputation
require(bnstruct)
predictors <-knn.impute(processPredictors, k = 5) %>% as.data.frame
ProcessPredictors
ChemicalManufacturingProcess
#knn imputation
require(bnstruct)
predictors <-knn.impute(ChemicalManufacturingProcess, k = 5) %>% as.data.frame %>% subset(select=-c(Yield))
predictors <-knn.impute(ChemicalManufacturingProcess, k = 5)
predictors <-knn.impute(as.data.frame(ChemicalManufacturingProcess), k = 5)
ChemicalManufacturingProcess %>% as.data.frame()
train = as.data.frame(ChemicalManufacturingProcess)
train = as.data.frame(ChemicalManufacturingProcess) %>% subset(select=-c(Yield))
train
train$Yield
bnstruct::knn.impute(train)
str(train)
require(Hmisc)
impute(train)
impute(ChemicalManufacturingProcess)
impute(ChemicalManufacturingProcess[1,])
df = impute(ChemicalManufacturingProcess)
df
df$BiologicalMaterial01
df$Yield
#knn imputation
require(bnstruct)
predict = as.data.frame(ChemicalManufacturingProcess) %>% subset(select=-c(Yield))
predict = impute(predict)
response   <-ChemicalManufacturingProcess$Yield %>% as.data.frame
predict
head(predict)
head(predict[1,])
predict[1,]
predict[1]
predict[1,]
ChemicalManufacturingProcess
ChemicalManufacturingProcess %>% as.matrix
ChemicalManufacturingProcess %>% as.matrix %>% data.frame
predict = (ChemicalManufacturingProcess) %>% subset(select=-c(Yield)) %>% as.matrix %>% data.frame
impute(predict)
predict = (ChemicalManufacturingProcess) %>% subset(select=-c(Yield)) %>% data.frame
predict = impute(predict)
response   <-ChemicalManufacturingProcess$Yield %>% as.data.frame
plot(predict)
plot(predict)
plot(response)
hist(response)
hist(predict)
nearZeroVar(predict)
predict[7]
#remove nzv
nzv = nearZeroVar(predictors)
require(bnstruct)
predictors = (ChemicalManufacturingProcess) %>% subset(select=-c(Yield)) %>% data.frame
predictors = impute(predictors)
response  <-ChemicalManufacturingProcess$Yield %>% as.data.frame
#remove nzv
nzv = nearZeroVar(predictors)
nzv
predictors[-nzv]
predictors[-nzv]%>% length
predictors %>% length
predictors = predictors[-nzv]
#knn imputation
require(bnstruct)
predictors = (ChemicalManufacturingProcess) %>% subset(select=-c(Yield)) %>% data.frame
predictors = impute(predictors)
response  <-ChemicalManufacturingProcess$Yield %>% as.data.frame
#remove nzv
nzv = nearZeroVar(predictors)
predictors = predictors[-nzv]
#create data partition for training
set.seed(1)
trainingRows <- createDataPartition(predictors[,1],p = 0.80, list=FALSE)
trainPredict <- predictors[trainingRows,]
trainResponse<- response[trainingRows,]
testPredict  <- predictors[-trainingRows,]
testResponse <- response[-trainingRows,]
#pre-process data
pp.train <- preProcess(trainPredict,method=c("center","scale","BoxCox"))
pp.test  <- preProcess(testPredict,method=c("center","scale","BoxCox"))
trainPredict <- predict(pp.train,newdata=trainPredict)
testPredict  <- predict(pp.test,newdata=testPredict)
#model 3: pls
require(pls)
require(dplyr)
set.seed(1)
pls <- train(x=trainPredict,y=trainResponse, method="pls",tunelength=20,trControl = ctrl, preProc=c("center","scale"))
pls.predict <- predict(pls,newdata = testPredict) %>% as.numeric()
print(RMSE(pls.predict,testResponse))
print(caret::R2(pls.predict,testResponse))
print(paste("Optimal tuning parameter: number of components",pls$bestTune$ncomp))
xyplot(pls.predict~testResponse,type=c("p","g"),xlab="predicted",ylab="observed",main="Observed vs. predicted values for pls")
#model 3: pls
require(pls)
require(dplyr)
set.seed(1)
pls <- train(x=trainPredict,y=trainResponse, method="pls",tunelength=20,trControl = ctrl)
pls.predict <- predict(pls,newdata = testPredict) %>% as.numeric()
#est metric
print(RMSE(pls.predict,testResponse))
print(caret::R2(pls.predict,testResponse))
print(paste("Optimal tuning parameter: number of components",pls$bestTune$ncomp))
xyplot(pls.predict~testResponse,type=c("p","g"),xlab="predicted",ylab="observed",main="Test: Observed vs. predicted values for pls")
pls$results
#train metric
print(pls$results)
#est metric
print(RMSE(pls.predict,testResponse))
print(caret::R2(pls.predict,testResponse))
print(paste("Optimal tuning parameter: number of components",pls$bestTune$ncomp))
xyplot(pls.predict~testResponse,type=c("p","g"),xlab="predicted",ylab="observed",main="Test: Observed vs. predicted values for pls")
#model 3: pls
require(pls)
require(dplyr)
set.seed(1)
pls <- train(x=trainPredict,y=trainResponse, method="pls",tunelength=40,trControl = ctrl)
pls.predict <- predict(pls,newdata = testPredict) %>% as.numeric()
#train metric
print(pls$results)
#est metric
print(RMSE(pls.predict,testResponse))
print(caret::R2(pls.predict,testResponse))
print(paste("Optimal tuning parameter: number of components",pls$bestTune$ncomp))
xyplot(pls.predict~testResponse,type=c("p","g"),xlab="predicted",ylab="observed",main="Test: Observed vs. predicted values for pls")
pls$method
pls$maximize
pls$modelInfo
pls$modelType
pls$results
pls$pred
pls$bestTune
pls$call
pls$dots
pls$metric
pls$control
pls$finalModel
pls$levels
pls$times
pls$perfNames
pls$resampledCM
library(glmnet)
require(caret)
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(as.matrix(trainPredict), trainResponse, alpha = 0.5)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_model <- glmnet(as.matrix(trainPredict), trainResponse, alpha = 0.5, lambda = best_lambda)
lasso <- predict(best_model, s = best_lambda, newx = as.matrix(testPredict))
print(caret::R2(lasso,testResponse))
print(caret::RMSE(lasso,testResponse))
best_model
best_model$beta
best_model$a0
best_model$beta
best_model$df
best_model$dim
best_model$lambda
best_model$dev.ratio
best_model$nulldev
best_model$npasses
best_model$nobs
best_model$call
best_model$offset
best_model$jerr
R2(best_model)
summary(best_model)
resid(best_model)
resid()
plot(cv_model)
best_lambda
log(best_lambda)
MSE(cv_model)
cv_model$cvm
cv_model$cvm %>% min
cv_model$cvm %>% min %>% sqrt
best_model$cvm
best_lambda <- cv_model$lambda.min
best_model <- cv.glmnet(as.matrix(trainPredict), trainResponse, alpha = 0.5, lambda = best_lambda)
#print test metrics
print(caret::R2(lasso,testResponse))
print(caret::RMSE(lasso,testResponse))
#print train metrics
print(cv_model$cvm %>% min %>% sqrt)
```{r}
library(glmnet)
require(caret)
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(as.matrix(trainPredict), trainResponse, alpha = 0.5)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_model <- glmnet(as.matrix(trainPredict), trainResponse, alpha = 0.5, lambda = best_lambda)
lasso <- predict(best_model, s = best_lambda, newx = as.matrix(testPredict))
#print test metrics
print(caret::R2(lasso,testResponse))
print(caret::RMSE(lasso,testResponse))
#print train metrics
print(cv_model$cvm %>% min %>% sqrt)
```
library(glmnet)
require(caret)
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(as.matrix(trainPredict), trainResponse, alpha = 0.5)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_model <- glmnet(as.matrix(trainPredict), trainResponse, alpha = 0.5, lambda = best_lambda)
lasso <- predict(best_model, s = best_lambda, newx = as.matrix(testPredict))
#print test metrics
print(caret::R2(lasso,testResponse))
print(caret::RMSE(lasso,testResponse))
#print train metrics
print(cv_model$cvm %>% min %>% sqrt)
lasso
best_model
best_model$beta
sort[best_model$beta]
sort(best_model$beta)
best_model$beta
best_model$beta[1,]
best_model$beta[,1]
best_model$beta > 0
best_model$beta %>% as.data.frame()
best_model$beta %>% as.matrix
best_model$beta$s0
best_model$beta
subset(best_model$beta,best_model$beta>0)
lasso$beta
best_model$beta
best_model$beta %>% str()
best_model$beta %>% as.data.frame
best_model$beta %>% summary
best_model$beta[1]
best_model$beta[1,]
best_model$beta[,1]
names(best_model$beta)
unique(best_model$beta)
predictors
predictors.top <- subset(predictors,subset=-preds)
preds = c("BiologicalMaterial05","BiologicalMaterial06","BiologicalMaterial12","ManufacturingProcess39","ManufacturingProcess37","ManufacturingProcess36","ManufacturingProcess32","ManufacturingProcess17","ManufacturingProcess15","ManufacturingProcess13","ManufacturingProcess9")
predictors.top <- subset(predictors,subset=-preds)
preds = c("BiologicalMaterial05","BiologicalMaterial06","BiologicalMaterial12","ManufacturingProcess39","ManufacturingProcess37","ManufacturingProcess36","ManufacturingProcess32","ManufacturingProcess17","ManufacturingProcess15","ManufacturingProcess13","ManufacturingProcess9")
predictors.top <- subset(predictors,subset=-c("BiologicalMaterial05","BiologicalMaterial06","BiologicalMaterial12","ManufacturingProcess39","ManufacturingProcess37","ManufacturingProcess36","ManufacturingProcess32","ManufacturingProcess17","ManufacturingProcess15","ManufacturingProcess13","ManufacturingProcess9"))
predictors.top <- subset(predictors,select=-preds)
preds = c("BiologicalMaterial05","BiologicalMaterial06","BiologicalMaterial12","ManufacturingProcess39","ManufacturingProcess37","ManufacturingProcess36","ManufacturingProcess32","ManufacturingProcess17","ManufacturingProcess15","ManufacturingProcess13","ManufacturingProcess9")
predictors.top <- subset(predictors,select=-preds)
predictors.top <- subset(predictors,select=-c("BiologicalMaterial05","BiologicalMaterial06","BiologicalMaterial12","ManufacturingProcess39","ManufacturingProcess37","ManufacturingProcess36","ManufacturingProcess32","ManufacturingProcess17","ManufacturingProcess15","ManufacturingProcess13","ManufacturingProcess9"))
predictors.top <- subset(predictors,select=-c(BiologicalMaterial05,BiologicalMaterial06,BiologicalMaterial12,ManufacturingProcess39,ManufacturingProcess37,ManufacturingProcess36,ManufacturingProcess32,ManufacturingProcess17,ManufacturingProcess15,ManufacturingProcess13,ManufacturingProcess9))
predictors$ManufacturingProcess09
predictors.top <- subset(predictors,select=-c(BiologicalMaterial05,BiologicalMaterial06,BiologicalMaterial12,ManufacturingProcess39,ManufacturingProcess37,ManufacturingProcess36,ManufacturingProcess32,ManufacturingProcess17,ManufacturingProcess15,ManufacturingProcess13,ManufacturingProcess09))
predictors
response
plot(x=predictors.top$BiologicalMaterial01,y=response)
predictors.top$BiologicalMaterial01%>%nrow
predictors.top$BiologicalMaterial01%>%nrow
predictors.top$BiologicalMaterial01%>%length
response%>%length
responses
response
response%>%length
responses%>%length
nrow(response)
nrow(predictors.top)
plot(x=predictors.top$BiologicalMaterial01,y=responses)
plot(x=predictors.top$BiologicalMaterial01,y=response)
predictors.top$BiologicalMaterial01 %>% length
response%>%nrow
predictors.top <- subset(ChemicalManufacturingProcess,select=-c(BiologicalMaterial05,BiologicalMaterial06,BiologicalMaterial12,ManufacturingProcess39,ManufacturingProcess37,ManufacturingProcess36,ManufacturingProcess32,ManufacturingProcess17,ManufacturingProcess15,ManufacturingProcess13,ManufacturingProcess09,Yield))
#a. visualize.
require(corrplot)
#extract predictors into correlogram
predictors.cor = cor(predictors.top)
corrplot(predictors.cor,order="hclust")
predictors.cor
predictors.top <- subset(ChemicalManufacturingProcess,select=c(BiologicalMaterial05,BiologicalMaterial06,BiologicalMaterial12,ManufacturingProcess39,ManufacturingProcess37,ManufacturingProcess36,ManufacturingProcess32,ManufacturingProcess17,ManufacturingProcess15,ManufacturingProcess13,ManufacturingProcess09,Yield))
#a. visualize.
require(corrplot)
#extract predictors into correlogram
predictors.cor = cor(predictors.top)
corrplot(predictors.cor,order="hclust")
predictors.cor
predictors.top$ManufacturingProcess36
predictors.top = impute(predictors.top)
#a. visualize.
require(corrplot)
#extract predictors into correlogram
predictors.cor = cor(predictors.top)
corrplot(predictors.cor,order="hclust",)
order(predictors.top)
#knn imputation
require(bnstruct)
predictors = (ChemicalManufacturingProcess) %>% subset(select=-c(Yield)) %>% data.frame
predictors = impute(predictors)
response  <-ChemicalManufacturingProcess$Yield %>% as.data.frame
#remove nzv
nzv = nearZeroVar(predictors)
predictors = predictors[-nzv]
#knn imputation
require(Hmisc)
predictors = Hmisc::impute(predictors)
